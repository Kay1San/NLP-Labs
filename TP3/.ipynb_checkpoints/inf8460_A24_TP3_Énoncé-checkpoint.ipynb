{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G9ZPAA_02tRR"
   },
   "source": [
    "##### INF8460 – Traitement automatique de la langue naturelle - Automne 2024\n",
    "\n",
    "## TP3: Génération automatique de mots-clés (concepts) avec une architecture Transformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NWO5vIjG2tRS"
   },
   "source": [
    "## Identification de l'équipe:\n",
    "\n",
    "### Groupe de laboratoire:\n",
    "\n",
    "### Equipe numéro :\n",
    "\n",
    "### Membres:\n",
    "\n",
    "- membre 1 (% de contribution, nature de la contribution)\n",
    "- membre 2 (% de contribution, nature de la contribution)\n",
    "- membre 3 (% de contribution, nature de la contribution)\n",
    "\n",
    "* nature de la contribution: Décrivez brièvement ce qui a été fait par chaque membre de l’équipe. Tous les membres sont censés contribuer au développement. Bien que chaque membre puisse effectuer différentes tâches, vous devez vous efforcer d’obtenir une répartition égale du travail. Soyez précis ! N'indiquez pas seulement : travail réparti équitablement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1FayMA0Z9Fxp"
   },
   "source": [
    "## 1. Objectif du TP\n",
    "\n",
    "Dans ce TP, vous allez devoir implémenter en `PyTorch` un modèle suivant l'architecture Transformer créée initialement dans l'article \"[Attention Is All You Need](https://arxiv.org/pdf/1706.03762)\".\n",
    "<br>\n",
    "Votre tâche sera d'implémenter l'architecture du Transformer et d'entraîner un modèle de type Transformer à générer les concepts clés d'une phrase. Votre modèle prendra donc en entrée une phrase quelconque en anglais et produira en sortie une séquence de mots correspondant aux concepts les plus importants de la phrase. Par exemple :\n",
    "<br>\n",
    "\n",
    "**Entrée** : \"The dog jumped over the fence.\" <br>\n",
    "**Sortie attendue** : ['dog' 'jump' 'fence']\n",
    "\n",
    "Cette tâche a d'ailleurs plusieurs applications dans le monde réel allant de la génération de résumés jusqu'à la création de bases de connaissances à partir d'un texte.\n",
    "\n",
    "\n",
    "#### Requis et ressources utiles\n",
    "\n",
    "Il est fortement conseillé de s'être familiarisé avec la librairie `PyTorch` avant d'entamer le TP. Par exemple, vous devriez savoir comment fonctionne un objet de type `nn.Module` et ce que la fonction `forward` de cet objet fait. Plusieurs tutoriels sont disponibles sur internet expliquant clairement le fonctionnement de la librairie. Voici certaines ressources qui peuvent être utiles :\n",
    "- [Build The Neural Network](https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html)\n",
    "- [PyTorch Tutorial](https://github.com/yunjey/pytorch-tutorial?tab=readme-ov-file)\n",
    "\n",
    "\n",
    "## 2. Jeu de données\n",
    "\n",
    "Le jeu de données est composé de paires (phrase, concepts) où une phrase est mentionnée et la liste des concepts les plus importants de la phrase est indiquée. Le jeu de données est divisé en ensembles d'entraînement, de validation et de test :\n",
    "- Entraînement : 4500 examples (train.csv)\n",
    "- Validation : 500 examples (val.csv)\n",
    "- Test : 500 examples (test.csv)\n",
    "\n",
    "Pour une même séquence de concepts, il y a 3 phrases pouvant être associées à ces concepts. Par exemple, pour les concepts : ['cat' 'laptop' 'lie'], les phrases suivantes y sont associées :\n",
    "- A cat lying on a laptop\n",
    "- A large cat lies down next to a laptop.\n",
    "- There is a cat lying on top of the laptop.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26Qe_-7z25EE"
   },
   "source": [
    "## 3. LIBRAIRIES PERMISES\n",
    "- Jupyter notebook\n",
    "- PyTorch\n",
    "- nltk\n",
    "- transformers\n",
    "- pandas\n",
    "- matplotlib\n",
    "- numpy\n",
    "- Huggingface\n",
    "\n",
    "\n",
    "Pour toute autre librairie, demandez à votre chargé de laboratoire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ssmtsfa12_CQ"
   },
   "source": [
    "## 4. INFRASTRUCTURE\n",
    "\n",
    "- Vous avez accès aux GPU du local L-4818. Dans ce cas, vous devez utiliser le dossier temp (voir le tutoriel VirtualEnv.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hn5uuxc59Fxp"
   },
   "source": [
    "## 5. ÉTAPES DU TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "eNlUvpo32tRS"
   },
   "outputs": [],
   "source": [
    "# Pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as O\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# ML\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# System\n",
    "from dataclasses import dataclass\n",
    "import time\n",
    "import re\n",
    "\n",
    "# Huggingface\n",
    "from tokenizers import CharBPETokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce GTX 1070\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())  # Should return True if CUDA is available\n",
    "print(torch.cuda.get_device_name(0))  # Should return 'GTX 1070'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZHahteTL9Fxq"
   },
   "source": [
    "Il vous faudra peut-être télécharger ce module de `nltk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xAjX6Fzz9MjK",
    "outputId": "e42b2184-6430-4742-814b-71076ab73024"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\K-1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AIwDxV0G2tRS"
   },
   "source": [
    "### 1. Charger les données (2 points)\n",
    "\n",
    "La première étape va être de charger les données des fichiers d'entraînement et d'évaluation. Pour cela, nous allons utiliser la classe `Dataset` de `PyTorch`. Complétez les fonctions de cette classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Ppkz_YFb2tRS"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, file_path: str = None, data: pd.DataFrame = None):\n",
    "\n",
    "        if file_path is None and data is None:\n",
    "            raise Exception('A file path or a dataframe must be passed to create a CustomDataset')\n",
    "\n",
    "        if file_path != None:\n",
    "            self.data = pd.read_csv(file_path)\n",
    "        else:\n",
    "            self.data = data.copy()\n",
    "\n",
    "        # TODO : Enlever les données qui sont nulles et\n",
    "        # assigner le résultat dans la variable data\n",
    "        self.data = self.data.dropna()\n",
    "        # END TODO\n",
    "\n",
    "    def __len__(self):\n",
    "        # TODO : Retourne le nombre de données\n",
    "        return self.data.shape[0]\n",
    "        # END TODO\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        # TODO : Retourne l'élément à l'index \"idx\"\n",
    "        return self.data.iloc[idx]\n",
    "        # END TODO\n",
    "\n",
    "    def get_column(self, column: str):\n",
    "        # TODO : Retourne toutes les rangées de la colonne \"column\"\n",
    "        return self.data[column]\n",
    "        # END TODO\n",
    "\n",
    "    def get_batch(self, idx: int, size):\n",
    "        # TODO : Retourne toutes les rangées de l'index \"idx\" à \"idx\" + \"size\"\n",
    "        return self.data.iloc[idx:idx+size]\n",
    "        # END TODO\n",
    "\n",
    "    def transform(self, function):\n",
    "        self.data = self.data.apply(function)\n",
    "\n",
    "    def sample(self, nb_samples, random_state=42):\n",
    "        return self.data.sample(n=nb_samples, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "2CWT0dXF2tRT"
   },
   "outputs": [],
   "source": [
    "root = 'data/'\n",
    "\n",
    "train_dataset = CustomDataset(root + 'train.csv')\n",
    "test_dataset = CustomDataset(root + 'test.csv')\n",
    "val_dataset = CustomDataset(root + 'val.csv')\n",
    "\n",
    "INPUT_COLUMN = 'sentence'\n",
    "OUTPUT_COLUMN = 'concepts'\n",
    "MAX_LENGTH = 16\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu' # Vous pouvez changer sur quelle machine les calculs seront effectués"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rv_Bjpg92tRT",
    "outputId": "5e243af9-f973-40dc-eaee-dda6ea02d0b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size :  4500\n",
      "Validation set size :  500\n",
      "Testing set size :  500\n"
     ]
    }
   ],
   "source": [
    "print('Training set size : ', len(train_dataset))\n",
    "print('Validation set size : ', len(val_dataset))\n",
    "print('Testing set size : ', len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c-HmDFdv2tRT"
   },
   "source": [
    "### 2. Statistiques (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p92b0tB79Fxr"
   },
   "source": [
    "Avant d'entamer la création du modèle, il est important de se familiariser avec les données et d'évaluer la taille des données avec lesquelles nous travaillons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5oOmXpLE2tRT"
   },
   "source": [
    "#### 2.1 Histogramme du nombre de caractères (2 points)\n",
    "\n",
    "Complétez la méthode `show_histogram_nb_characters` qui affiche un histogramme de la distribution du nombre de caractères des exemples de la colonne passée en paramètre. L'axe des abscisses devra représenter le nombre de caractères et l'axe des ordonnées le nombre de documents. Utilisez des bacs (bins) de 20 pour l'histogramme. Affichez ensuite la distribution du nombre de caractères sur l'ensemble d'entraînement pour la colonne 'sentence' et la colonne 'concepts'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 887
    },
    "id": "38GHBsHZ2tRT",
    "outputId": "20d88c6c-9902-4cc6-a66d-d3ce2737da3e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_histogram_nb_chararacters(dataset: CustomDataset, column: str):\n",
    "\n",
    "    \"\"\"\n",
    "    Affiche la distribution de la colonne passé en paramètre. L'histogramme doit contenir un titre et des titres sur les axes\n",
    "\n",
    "    dataset: Dataset contenant plusieurs colonne dont la colonne dont les statistiques doivent être affichées\n",
    "    column: Colonne à afficher\n",
    "\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    dataset.data[\"string_characters\"] = dataset.get_column(column).apply(lambda x: len(x))\n",
    "\n",
    "    dataset.data.hist(\"string_characters\", bins=20)\n",
    "\n",
    "    # END TODO\n",
    "\n",
    "\n",
    "show_histogram_nb_chararacters(train_dataset, INPUT_COLUMN)\n",
    "show_histogram_nb_chararacters(train_dataset, OUTPUT_COLUMN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zOOUTrZU2tRT"
   },
   "source": [
    "#### 2.2 Histogramme du nombre de mots par document (2 points)\n",
    "\n",
    "De la même manière, complétez la méthode `show_histogram_nb_words` qui affiche un histogramme de la distribution du nombre de mots des exemples de la colonne passée en paramètre. Utilisez des bacs (bins) de 20 pour l'histogramme. Affichez ensuite la distribution du nombre de mots sur l'ensemble d'entraînement pour les colonnes \"sentence\" et \"concepts\". Dans le cas de la colonne 'concepts', assurez-vous que les '[', ']' et les apostrophes ne soient pas considérées comme des mots.\n",
    "\n",
    "Indice : Utilisez la méthode word_tokenize() de nltk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "wq97r1Yc2tRT",
    "outputId": "be10bf0c-4287-4c0b-9f56-c8b0d6e55e07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Column :  sentence\n",
      "0                            Skier skis down the mountain\n",
      "1                      A skier is skiing down a mountain.\n",
      "2            Three skiers are skiing on a snowy mountain.\n",
      "3                            The dog is wagging his tail.\n",
      "4                         A dog wags his tail at the boy.\n",
      "                              ...                        \n",
      "4495        A baby elephant walking along side its mother\n",
      "4496    a big elephant and small one walking side by side\n",
      "4497                           winding road in a mountain\n",
      "4498                         winding road up the mountain\n",
      "4499        roads wind around and between the mountains .\n",
      "Name: sentence, Length: 4500, dtype: object\n",
      "For Column :  concepts\n",
      "0       ['mountain' 'ski' 'skier']\n",
      "1       ['mountain' 'ski' 'skier']\n",
      "2       ['mountain' 'ski' 'skier']\n",
      "3             ['dog' 'tail' 'wag']\n",
      "4             ['dog' 'tail' 'wag']\n",
      "                   ...            \n",
      "4495    ['elephant' 'side' 'walk']\n",
      "4496    ['elephant' 'side' 'walk']\n",
      "4497    ['mountain' 'road' 'wind']\n",
      "4498    ['mountain' 'road' 'wind']\n",
      "4499    ['mountain' 'road' 'wind']\n",
      "Name: concepts, Length: 4500, dtype: object\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_nb_words(data_row: str):\n",
    "    tokens = nltk.word_tokenize(data_row)\n",
    "    tokens = [token for token in tokens if token not in ['[', ']', \"'\"]]\n",
    "    return len(tokens)\n",
    "\n",
    "\n",
    "def show_histogram_nb_words(dataset: CustomDataset, column: str):\n",
    "\n",
    "    \"\"\"\n",
    "    Affiche la distribution de la colonne passé en paramètre du dataset. L'histogramme doit contenir un titre et des titres sur les axes\n",
    "\n",
    "    dataset: Dataset contenant plusieurs colonne dont la colonne dont les statistiques doivent être affichées\n",
    "    column: Colonne à afficher\n",
    "\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    print(\"For Column : \", column)\n",
    "    print(dataset.get_column(column))\n",
    "    dataset.data[\"nb_words\"] = dataset.get_column(column).apply(lambda x: get_nb_words(x))\n",
    "    dataset.data.hist(\"nb_words\", bins=20)\n",
    "    # END TODO\n",
    "\n",
    "show_histogram_nb_words(train_dataset, INPUT_COLUMN)\n",
    "show_histogram_nb_words(train_dataset, OUTPUT_COLUMN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fKAGNVSe2tRT"
   },
   "source": [
    "#### 2.3 Commentez les graphiques (1 points)\n",
    "1. Est-ce que les distributions suivent des distributions normales ?\n",
    "2. Qu'observez-vous de spécial sur la distribution du nombre de mots de la colonne \"concepts\" ? Pourquoi est-elle ainsi ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gkHu38HUE7sA"
   },
   "source": [
    "1. Pour ce qui est des histogrames sur le nombre de caractères, on observe que celle-ci contient une distribution qui ressemble plus à celle de la loi normale sachant qu'elle est plutôt centré vers la moyenne tandis que ceci n'est aucunement le cas pour les histogrames sur le nombre de mots en voyant même que certains valeurs de l'axe des x ne contiennent aucune valeur.\n",
    "\n",
    "2. L'histograme de la column concept est tel qu'elle est puisqu'elle représente la normalisation des mots de la colonne concepts pour la quelle on a retiré les stop words, ce qui fait que chaque rangée à uniquement 3 mots pertinents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EDnurIIU2tRT"
   },
   "source": [
    "### 3. Segmentation (Tokenization) (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BU1nJ3xT2tRT"
   },
   "source": [
    "#### 3.1 Entraînement du segmenteur (tokenizer) (3 points)\n",
    "La fonction `word_tokenize()` de `nltk` est utile pour rapidement ressortir des statistiques, mais elle reste très générale et inefficace. Afin de réduire le plus possible la taille du vocabulaire, nous allons entraîner notre propre Tokenizer en nous basant sur l'algorithme BPE (Byte Pair Encoding). L'algorithme BPE est une méthode de compression de texte qui permet de créer des tokenizers efficaces en regroupant les caractères les plus fréquents. Il commence par diviser le texte en caractères uniques, puis itérativement fusionne les paires de caractères les plus fréquentes en nouveaux symboles. Ce processus continue jusqu'à atteindre un nombre prédéfini de jetons (tokens), permettant ainsi de gérer des vocabulaires de différentes tailles de manière flexible et efficace. À l'aide de BPE, nous allons transformer les mots en nombres pour pouvoir les passer au Transformer par la suite. Chaque jeton (token) sera associé à un nombre correspondant à l'indice du jeton dans le vocabulaire. Une séquence en entrée sera ainsi représentée comme une séquence de nombres.\n",
    "\n",
    "De plus, des jetons spéciaux seront ajoutés au tokenizer pour spécifier le début d'une phrase (begin-of-sequence : `[BOS]`) et la fin d'une phrase (end-of-sequence : `[EOS]`). Un jeton de padding `[PAD]` sera utilisé afin de s'assurer que toutes les phrases ont la même taille. Finalement, un jeton `[UNK]` sera utilisé pour les jetons inconnus.\n",
    "\n",
    "Pour créer ce vocabulaire à l'aide de l'algorithme BPE, il faudra entraîner le tokenizer sur notre ensemble d'entraînement pour qu'il puisse encoder efficacement les mots qui y sont présents. L'entraînement est déjà implémenté par la classe `ByteLevelBPYTokenizer` de la librairie `tokenizers`.\n",
    "\n",
    "Vous n'avez qu'à compléter la fonction :\n",
    "- `data_generator` qui retourne un générateur d'un lot (batch) de texte provenant de l'ensemble d'entraînement. Pour chaque lot, les colonnes \"sentence\" et \"concepts\" sont concaténées pour former la chaîne finale qui sera envoyée au tokenizer. Les lots sont utiles lors de l'entraînement pour accélérer l'entraînement en parallélisant le tout et en évitant de charger tout notre ensemble d'entraînement en mémoire directement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "T7ouSYOn9Fxr"
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 8000\n",
    "special_tokens = ['[PAD]', '[BOS]', '[EOS]', '[UNK]']\n",
    "base_tokenizer = CharBPETokenizer(unk_token=special_tokens[-1])\n",
    "tokenizer_batch_size = 64\n",
    "\n",
    "def data_generator():\n",
    "    \"\"\"\n",
    "    Generateur qui retourne un lot (batch) de texte provenant de l'ensemble d'entraînement.\n",
    "    Pour chaque élément d'un lot, les colonnes \"target\" et \"concepts\" sont concaténée.\n",
    "    \"\"\"\n",
    "    for i in range(0, len(train_dataset), tokenizer_batch_size):\n",
    "\n",
    "        # TODO\n",
    "        batch = train_dataset.get_batch(i, tokenizer_batch_size)\n",
    "        text = batch[\"sentence\"] + batch[\"concepts\"] # Mettez le lot dans la variable text\n",
    "        # END TODO\n",
    "\n",
    "\n",
    "        yield text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JS-nxpFN9Fxr"
   },
   "source": [
    "Vous devez maintenant compléter la fonction :\n",
    "- `train_tokenizer` qui prend en paramètre un tokenizer pour entraîner ce dernier à l'aide de la fonction [train_from_iterator](https://github.com/huggingface/tokenizers/blob/main/bindings/python/py_src/tokenizers/implementations/byte_level_bpe.py). Le générateur de données (data_generator) est envoyé à la fonction train_from_iterator tout comme la taille du vocabulaire, les jetons spéciaux et la fréquence minimum d'une séquence pour la considérer comme un jeton. Indiquez explicitement une fréquence minimum de 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Xhy4Axwq9Fxr"
   },
   "outputs": [],
   "source": [
    "\n",
    "from tokenizers import AddedToken, Tokenizer, decoders, pre_tokenizers, processors, trainers\n",
    "\n",
    "def train_tokenizer(tokenizer: CharBPETokenizer):\n",
    "    \"\"\"\n",
    "    Entraîne le tokenizer passé en paramètre en appelant la fonction train_from_iterator\n",
    "    et en spécifiant le générateur de donnée (data_generator), la taille du vocabulaire,\n",
    "    les jetons spéciaux et une fréquence minimum de 2 (indiquez le explicitement)\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    tokenizer.train_from_iterator(data_generator(), vocab_size=VOCAB_SIZE, min_frequency=2, special_tokens=special_tokens)\n",
    "    # END TODO\n",
    "\n",
    "train_tokenizer(base_tokenizer)\n",
    "\n",
    "# On ajoute les jetons de début, de fin de phrase et de jeton inconnu\n",
    "bos_token_id = base_tokenizer.token_to_id(\"[BOS]\")\n",
    "eos_token_id = base_tokenizer.token_to_id(\"[EOS]\")\n",
    "unk_token_id = base_tokenizer.token_to_id(\"[UNK]\")\n",
    "\n",
    "# On applique un template au tokenizer pour qu'il ajoute\n",
    "# les jetons au début et à la fin de chaque phrase\n",
    "base_tokenizer.post_processor = processors.TemplateProcessing(\n",
    "    single=f\"[BOS]:0 $A:0 [EOS]:0\",\n",
    "    special_tokens=[\n",
    "        (\"[BOS]\", bos_token_id),\n",
    "        (\"[EOS]\", eos_token_id),\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "goTLCnvu9Fxr"
   },
   "source": [
    "Nous allons maintenant transformer notre tokenizer pour qu'il soit compatible avec l'API de la librairie Huggingface. Cela permettra entre autre de faciliter les appels de méthodes pour modifier facilement nos entrées. Par exemple, avec l'API de Huggingface, nous pouvons simplement appeler la méthode `tokenize` pour diviser une séquence en jetons (`Welcome` -> `[W, el, come]`). De la même manière, l'API nous permet d'appeler les méthodes `encode` et `decode` pour transformer une chaîne de caractères en séquences d'indices de jetons (`Welcome` -> `[36, 170, 664]`) et inversement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lFU2lsU52tRU",
    "outputId": "ec340b13-dbad-4e1a-923c-131d171dc927"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\K-1\\anaconda3\\envs\\myenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast(tokenizer_object=base_tokenizer._tokenizer, truncation=True)\n",
    "tokenizer.add_special_tokens({\n",
    "    'pad_token': \"[PAD]\",\n",
    "    'bos_token': \"[BOS]\",\n",
    "    'eos_token': \"[EOS]\",\n",
    "    'unk_token': \"[UNK]\"\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I1HQ12tm9Fxr"
   },
   "source": [
    "Testons maintenant notre tokenizer sur une phrase de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RXwsa-s92tRU",
    "outputId": "c83dbbf5-7de6-431d-d874-cc81ab4ae91a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome ! The boat arrived at the station ! 🤗  \n",
      "\n",
      "['W', 'el', 'come</w>', '!</w>', 'The</w>', 'boat</w>', 'arrived</w>', 'at</w>', 'the</w>', 'station</w>', '!</w>', '[UNK]']\n"
     ]
    }
   ],
   "source": [
    "test_input = 'Welcome ! The boat arrived at the station ! 🤗 '\n",
    "print(test_input, '\\n')\n",
    "print(tokenizer.tokenize(test_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M9VPYkgF9Fxr"
   },
   "source": [
    "Observons maintenant la même phrase, mais une fois encodée en nombre. Décodons-la ensuite à partir de sa version encodée pour voir si nous retrouvons la phrase initiale.\n",
    "\n",
    "- La méthode `encode` permet de transformer une séquence de mots en séquence de nombres correspondant aux indices des différents jetons de la phrase dans le vocabulaire\n",
    "- La méthode `decode` permet de transformer une séquence d'indices de jetons en phrase lisible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OGYIbuYw2tRU",
    "outputId": "b942b57d-6ef4-47bb-81a7-e9d1a3dc1d6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte initial :  Welcome ! The boat arrived at the station ! 🤗 \n",
      "====================================================================================================\n",
      "Texte encodé :  [1, 36, 170, 664, 103, 277, 274, 2907, 126, 118, 254, 103, 3, 2]\n",
      "Texte décodé :  [BOS]Welcome ! The boat arrived at the station ! [UNK][EOS]\n"
     ]
    }
   ],
   "source": [
    "print('Texte initial : ', test_input)\n",
    "print('=' * 100)\n",
    "print('Texte encodé : ', tokenizer.encode(test_input))\n",
    "print('Texte décodé : ', tokenizer.decode(tokenizer.encode(test_input)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bgAOmSe-9Fxr"
   },
   "source": [
    "#### 3.2 Que remarquez-vous dans la version segmentée (tokenized) de la phrase de test ? Quelles sont les différences entre la phrase initiale et la phrase décodée ? Pourquoi ? (2 points)\n",
    "Dans la phase initiale, on voit que la majorité des mots sont segmentés en caractères à l'exception de certain dont boat et station et que certains caractères sont considérèes comme unknown en raison de leur fréquence dont W dans Welcome et le point d'exclamation. La phrase décodée est en mesure de convertir les valeurs numériques en combinaison de caractères."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SJt5coCQ9Fxs"
   },
   "source": [
    "### 4. Transformer (28 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P2qoKbLl9Fxs"
   },
   "source": [
    "Il est maintenant le temps de construire les couches du Transformer. Son architecture globale est présentée dans la figure suivante. :\n",
    "\n",
    "![Transformer](images/transformer.png)\n",
    "\n",
    "Les couches sont définies pour vous et vous n'avez qu'à compléter, à moins d'indication contraire, la fonction `forward` de chacune des classes qui prend un tenseur en entrée et effectue une transformation sur celui-ci pour générer une sortie. Cette transformation varie en fonction de chaque classe. Une description de ce que doit faire la classe est indiquée à chaque étape. Lorsque la fonction `forward` est complexe, une figure est fournie pour vous guider. Attention, ne changez pas le constructeur ou le nom de la classe !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hxIkdQnH9Fxs"
   },
   "source": [
    "#### 4.1 Positional Embedding\n",
    "Le Transformer encode l'information de l'ordre des mots dans les plongements des mots. Des plongements de position sont calculés et ils sont ajoutés aux plongements de contexte. Dans ce cas-ci la classe `PositionalEmbedding` vous est donnée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "jWGyCzdH2tRU"
   },
   "outputs": [],
   "source": [
    "class PositionalEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    Cette classe a été prise de l'implémentation originale du papier 'Attention Is All You Need'\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, max_seq_length, embedding_dim):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        pe = torch.zeros(max_seq_length, self.embedding_dim)\n",
    "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, self.embedding_dim, 2).float() * -(math.log(10000.0) / self.embedding_dim))\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return x + self.pe[:, :x.size(1)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qGaeIr1r9Fxs"
   },
   "source": [
    "#### 4.2 Attention (6 points)\n",
    "Le mécanisme d'attention est le coeur de l'architecture du Transformer. Il permet notamment la parallélisation de l'entraînement tout en garantissant un lien direct entre tous les jetons. Vous devrez implémenter la fonction `scaled_dot_product_attention` qui effectue le calcul principal derrière le mécanisme d'attention. Cette fonction prend en entrée les tenseurs `Q`, `K`, `V` et effectue le calcul suivant :\n",
    "$$A = \\texttt{softmax}\\Big( \\frac{Q K^T \\odot M}{\\sqrt{\\texttt{head\\_dim}}} \\Big) V$$\n",
    "où $M$ est le masque d'attention qui doit être appliqué. Plus de détails sont indiqués dans la description de la fonction à propos du masque. Par rapport au tenseur de clés, vous remarquerez dans la formule qu'une transposée est appliquée sur ce tenseur. Étant donné qu'un tenseur possède plus que 2 dimensions, il est important de spécifier quelles dimensions seront transposées dans le tenseur. Dans notre cas, il s'agit des dimensions correspondants aux jetons de la séquence et aux plongements des jetons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "lVVuGLFY2tRU"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, model_dim, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert model_dim % num_heads == 0, \"La dimension du modèle doit être divisible par le nombre de têtes d'attention\"\n",
    "\n",
    "        self.model_dim = model_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = model_dim // num_heads\n",
    "\n",
    "        self.wq = nn.Linear(model_dim, model_dim) # Query\n",
    "        self.wk = nn.Linear(model_dim, model_dim) # Key\n",
    "        self.wv = nn.Linear(model_dim, model_dim) # Value\n",
    "        self.wo = nn.Linear(model_dim, model_dim) # Output\n",
    "\n",
    "        self.mask_value = -1e9\n",
    "\n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        \"\"\"\n",
    "        Calcule les plongements d'attention en utilisant la formule\n",
    "\n",
    "        attn = softmax(Q * K^T @ mask / sqrt(head_dim)) * V\n",
    "\n",
    "        Args :\n",
    "            Q : plongements des queries\n",
    "            Taille : [batch_size, num_heads, seq_length, head_dim]\n",
    "\n",
    "            K : plongements des keys\n",
    "            Taille : [batch_size, num_heads, seq_length, head_dim]\n",
    "\n",
    "            V : plongement des values\n",
    "            Taille : [batch_size, num_heads, seq_length, head_dim]\n",
    "\n",
    "            mask : Masque d'attention qui doit être appliqué avant le softmax pour que\n",
    "            les jetons ne portent pas leur attention sur certains jetons. Le masque est\n",
    "            notamment utilisé dans le décodeur pour s'assurer que le transformer n'ait\n",
    "            pas accès aux futurs jetons lorsqu'il essaie de prédire le prochain jeton.\n",
    "            Il contient des valeurs 0 ou 1. Une valeur de 0 à la position i,j indique\n",
    "            que pour le jeton i, le jeton j doit être masqué. Pour masquer la valeur,\n",
    "            il suffit de mettre une valeur très petite (self.mask_value) à l'indice i,j.\n",
    "            La fonction masked_fill de PyTorch pourrait être utile\n",
    "            Taille : [1, seq_length, seq_length]\n",
    "\n",
    "        Returns :\n",
    "        Résultat du calcul d'attention de taille [batch_size, num_heads, seq_length, head_dim]\n",
    "        \"\"\"\n",
    "        # TODO\n",
    "        softmax = nn.Softmax(dim=3)\n",
    "        scores = torch.matmul(Q, K.transpose(2, 3))\n",
    "        scores = scores.masked_fill(mask == 0, self.mask_value)\n",
    "\n",
    "        scored_scaled = scores / math.sqrt(self.head_dim)\n",
    "        scored_softmax = softmax(scored_scaled)\n",
    "\n",
    "        output = torch.matmul(scored_softmax, V)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "        # END TODO\n",
    "\n",
    "    def split_heads(self, x):\n",
    "        \"\"\"\n",
    "        Sépare une entrée sur plusieurs têtes d'attention\n",
    "\n",
    "        Args :\n",
    "            x : Tenseur d'entrée\n",
    "            Taille : [batch_size, seq_length, model_dim]\n",
    "\n",
    "        Returns :\n",
    "        Tenseur séparé sur plusieurs têtes d'attention\n",
    "        Taille : [batch_size, num_heads, seq_length, head_dim]\n",
    "        \"\"\"\n",
    "        return x.view(x.shape[0], x.shape[1], self.num_heads, self.head_dim).transpose(1, 2)\n",
    "\n",
    "    def combine_heads(self, x):\n",
    "        \"\"\"\n",
    "        Combine une entrée à travers les têtes d'attention\n",
    "\n",
    "        Args :\n",
    "            x : Tenseur d'entrée\n",
    "            Taille : [batch_size, num_heads, seq_length, head_dim]\n",
    "\n",
    "        Returns :\n",
    "        Tenseur séparé sur plusieurs têtes d'attention\n",
    "        Taille : [batch_size, seq_length, model_dim]\n",
    "        \"\"\"\n",
    "        return x.transpose(1, 2).contiguous().view(x.shape[0], x.shape[2], self.model_dim)\n",
    "\n",
    "    def forward(self, queries, keys, values, mask=None):\n",
    "        \"\"\"\n",
    "        Exécute le mécanisme d'attention à travers plusieurs têtes\n",
    "        d'attention\n",
    "\n",
    "        Args :\n",
    "            queries : plongements des queries\n",
    "            Taille : [batch_size, seq_length, model_dim]\n",
    "\n",
    "            keys : plongements des keys\n",
    "            Taille : [batch_size, seq_length, model_dim]\n",
    "\n",
    "            values : plongement des values\n",
    "            Taille : [batch_size, seq_length, model_dim]\n",
    "\n",
    "            mask : mask qui sera appliqué\n",
    "            Taille : [1, seq_length, seq_length]\n",
    "\n",
    "        Returns :\n",
    "        Tenseur contenant les plongements finaux de chaque indice de\n",
    "        la séquence\n",
    "        Taille : [batch_size, seq_length, model_dim]\n",
    "        \"\"\"\n",
    "        Q = self.split_heads(self.wq(queries))\n",
    "        K = self.split_heads(self.wk(keys))\n",
    "        V = self.split_heads(self.wv(values))\n",
    "\n",
    "        #print('Shape of Q', Q.shape)\n",
    "        #print('Q Data : ', Q)\n",
    "\n",
    "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "        return self.wo(self.combine_heads(attn_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4RmDSGKW9Fxs",
    "outputId": "dbe99112-7067-40b3-b0bf-fa5622f62eb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASK is  torch.Size([1, 4, 4])\n",
      "tensor([[[-0.6789,  2.8487,  2.8666, -1.1983,  3.2915,  0.5359],\n",
      "         [-0.3437,  3.1045,  3.0715, -1.1405,  3.2748,  0.3843],\n",
      "         [-2.5825,  4.2728, -0.0114, -2.2663, -0.0922, -2.4731],\n",
      "         [-2.5749,  4.2706, -0.0056, -2.2613, -0.0874, -2.4694]]])\n"
     ]
    }
   ],
   "source": [
    "def test_attention():\n",
    "    batch_size = 1\n",
    "    seq_length = 4\n",
    "    model_dim = 6\n",
    "    num_heads = 2\n",
    "\n",
    "    torch.random.manual_seed(42)\n",
    "    attention = MultiHeadAttention(model_dim=model_dim, num_heads=num_heads)\n",
    "    inputs = torch.randint(0, 10, (batch_size, seq_length, model_dim), dtype=torch.float32)\n",
    "    mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1))\n",
    "    print('MASK is ', mask.shape)\n",
    "    print(attention.forward(inputs, inputs, inputs, mask=mask).detach())\n",
    "\n",
    "test_attention()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LYhfAMYn9Fxv"
   },
   "source": [
    "Sortie attendue :\n",
    "```\n",
    "tensor([[[-0.6789,  2.8487,  2.8666, -1.1983,  3.2915,  0.5359],\n",
    "         [-0.3437,  3.1045,  3.0715, -1.1405,  3.2748,  0.3843],\n",
    "         [-2.5825,  4.2728, -0.0114, -2.2663, -0.0922, -2.4731],\n",
    "         [-2.5749,  4.2706, -0.0056, -2.2613, -0.0874, -2.4694]]])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sWlUCL9J9Fxv"
   },
   "source": [
    "#### 4.3 Encodeur (6 points)\n",
    "L'encodeur du Transformer encode la séquence d'entrée dans des vecteurs de contexte avant d'envoyer ces vecteurs de contexte au décodeur pour qu'ils puissent être utilisés pour générer la séquence de sortie. Vous n'avez qu'à compléter les fonctions `forward` des classes `TransformerFeedForward`, `EncoderLayer` et `Encoder`. L'architecture d'une couche d'encodeur `EncoderLayer` est décrite dans la figure suivante :\n",
    "\n",
    "![EncoderLayer](images/encoder_layer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GXmZRBKw9Fxv"
   },
   "source": [
    "La classe `TransformerFeedForward` représente une couche simple de réseaux de neurones avec la fonction d'activation `ReLU` qui sera présente dans l'encodeur. Son architecture est décrite dans la figure suivante :\n",
    "\n",
    "![TransformerFeedForward](images/transformer_feed_forward.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "NtiCsab89Fxv"
   },
   "outputs": [],
   "source": [
    "class TransformerFeedForward(nn.Module):\n",
    "\n",
    "    def __init__(self, model_dim: int, ff_dim: int) -> None:\n",
    "        super(TransformerFeedForward, self).__init__()\n",
    "        self.model_dim = model_dim\n",
    "        self.ff_dim = ff_dim\n",
    "\n",
    "        self.ff1 = nn.Linear(model_dim, ff_dim)\n",
    "        self.ff2 = nn.Linear(ff_dim, model_dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Applique les deux couches linéaires (ff) consécutivement avec la fonction\n",
    "        d'activation ReLU après chaque couche linéaire\n",
    "\n",
    "        Args :\n",
    "            x : Tenseur d'entrée de taille [batch_size, model_dim]\n",
    "\n",
    "        Returns :\n",
    "        Tenseur après être passé à travers les couches linéaires de taille\n",
    "        [batch_size, model_dim]\n",
    "        \"\"\"\n",
    "        # TODO\n",
    "        x = self.ff1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.ff2(x)\n",
    "\n",
    "        return F.relu(x)\n",
    "        # END TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SOdPH-wA9Fxv"
   },
   "source": [
    "La classe `EncoderLayer` représente une seule couche qui applique le mécanisme d'attention sur la sortie de la couche précédente. Dans le cas de la première couche d'encodeur, il s'agit simplement de la couche de plongements des jetons. Par la suite, le résultat du mécanisme d'attention est normalisé et envoyé à une couche de réseau de neurones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "WM-OxKRy2tRU"
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, model_dim: int, ff_dim: int, dropout_rate: int = 0.3, num_heads=8) -> None:\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.self_attention = MultiHeadAttention(model_dim=model_dim, num_heads=num_heads)\n",
    "        self.feed_forward = TransformerFeedForward(model_dim=model_dim, ff_dim=ff_dim)\n",
    "        self.attention_layer_norm = nn.LayerNorm(model_dim)\n",
    "        self.ff_layer_norm = nn.LayerNorm(model_dim)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, encoder_mask: torch.Tensor = None):\n",
    "        \"\"\"\n",
    "        Applique la couche d'attention, de normalisation et de réseau de neurones\n",
    "        sur l'entrée\n",
    "\n",
    "        Args :\n",
    "            x : Tenseur d'entrée de l'encodeur correspondant à la séquence d'entrée\n",
    "            Taille : [batch_size, seq_length, model_dim]\n",
    "\n",
    "        Returns :\n",
    "        Tenseur après avoir appliqués les couches de taille [batch_size, seq_length,\n",
    "        model_dim]\n",
    "        \"\"\"\n",
    "        # TODO\n",
    "        # x -> self Attention + dropout -> x_tilde\n",
    "        x_tilde = self.dropout(\n",
    "            self.self_attention.forward(x,x,x,encoder_mask)\n",
    "        )\n",
    "        # x_tilde + x -> add + normalisation -> x_tilde_normalised\n",
    "        x_tilde_normalised = self.ff_layer_norm(x_tilde + x)\n",
    "\n",
    "        # x_tilde_normalised -> ff + dropout -> z\n",
    "        z = self.dropout(\n",
    "            self.feed_forward(x_tilde_normalised)\n",
    "        )\n",
    "\n",
    "        # z + x_tilde_normalised -> add + normalisation -> Y\n",
    "        Y = self.ff_layer_norm(z + x_tilde_normalised)\n",
    "\n",
    "        return Y\n",
    "        # END TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ktqwGE8r9Fxv"
   },
   "source": [
    "La classe `Encoder` correspond à une suite de plusieurs couches d'encodeurs. La fonction `forward` de cette classe doit appeler chacune des couches (`EncoderLayer`) une à la suite de l'autre en passant à la couche courante la sortie de la couche précédente. Le masque est partagé entre toutes les couches `EncoderLayer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "75n3oqTP2tRV"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, num_layers: int, model_dim: int, ff_dim: int, dropout_rate: int = 0.3, num_heads=8) -> None:\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.layers = nn.ModuleList(\n",
    "            [EncoderLayer(\n",
    "                model_dim=model_dim,\n",
    "                ff_dim=ff_dim,\n",
    "                dropout_rate=dropout_rate,\n",
    "                num_heads=num_heads,\n",
    "            ) for _ in range(num_layers)]\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor, encoder_mask: torch.LongTensor = None):\n",
    "        \"\"\"\n",
    "        Applique toutes les couches d'encodeur consécutivement\n",
    "\n",
    "        Args :\n",
    "            x : Tenseur d'entrée de l'encodeur correspondant à la séquence d'entrée\n",
    "            Taille : [batch_size, seq_length, model_dim]\n",
    "\n",
    "            encoder_mask : Tenseur contenant le masque qui sera utilisé par l'encodeur\n",
    "            pour cacher certains jetons (notamment les jetons [PAD])\n",
    "        Returns :\n",
    "        Tenseur après avoir appliqués les couches dans l'encodeur de taille\n",
    "        [batch_size, seq_length, model_dim]\n",
    "        \"\"\"\n",
    "        # TODO\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, encoder_mask)\n",
    "        return x\n",
    "        # END TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YBfB3AjY9Fxw"
   },
   "source": [
    "#### 4.4 Décodeur (8 points)\n",
    "Le décodeur est la partie du Transformer qui génère la séquence de sortie en prenant le contexte de la séquence d'entrée et les jetons qui ont été générés précédemment. De la même manière que l'encodeur, la classe `DecoderLayer` représente une seule couche de décodeur. L'architecture du `DecoderLayer` est présentée dans la figure suivante :\n",
    "\n",
    "![DecoderLayer](images/decoder_layer.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Fj8tGjvg2tRV"
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, model_dim: int, ff_dim: int, dropout_rate: int = 0.3, num_heads=8) -> None:\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.self_attention = MultiHeadAttention(model_dim=model_dim, num_heads=num_heads)\n",
    "        self.cross_attention = MultiHeadAttention(model_dim=model_dim, num_heads=num_heads)\n",
    "\n",
    "        self.feed_forward = TransformerFeedForward(model_dim=model_dim, ff_dim=ff_dim)\n",
    "\n",
    "        self.self_attention_layer_norm = nn.LayerNorm(model_dim)\n",
    "        self.cross_attention_layer_norm = nn.LayerNorm(model_dim)\n",
    "        self.ff_layer_norm = nn.LayerNorm(model_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self,\n",
    "                x: torch.Tensor,\n",
    "                encoder_out: torch.Tensor,\n",
    "                encoder_mask: torch.LongTensor = None,\n",
    "                decoder_mask: torch.LongTensor = None):\n",
    "        \"\"\"\n",
    "        Applique les couches d'attention, de normalisation et de réseau de neurones\n",
    "        sur l'entrée\n",
    "\n",
    "        Args :\n",
    "            x : Entrée du décodeur correspondant à la séquence de sortie décalée vers\n",
    "            la droite\n",
    "            Taille : [batch_size, seq_length, model_dim]\n",
    "\n",
    "            encoder_output : Sortie de l'encodeur utilisé pour la couche de cross-\n",
    "            attention\n",
    "            Taille : [batch_size, seq_length, model_dim]\n",
    "\n",
    "            encoder_mask : Masque qui cache certains jetons dans la séquence d'entrée.\n",
    "            Par exemple, les jetons [PAD] seront cachés puisqu'ils ne sont utilisés que\n",
    "            pour aggrandir les séquences jusqu'à la fenêtre de contexte du Transformer\n",
    "            Taille : [batch_size, seq_length, seq_length]\n",
    "\n",
    "            decoder_mask : Masque qui cache certains jetons dans la séquence de sortie.\n",
    "            Ce masque est notamment utilisé dans le décodeur pour s'assurer que le\n",
    "            transformer n'ait pas accès aux futurs jetons lorsqu'il essaie de prédire\n",
    "            le prochain jeton.\n",
    "            Taille : [batch_size, seq_length, seq_length]\n",
    "        \"\"\"\n",
    "        # TODO\n",
    "        # x -> self Attention + dropout -> x_tilde\n",
    "        x_tilde = self.dropout(\n",
    "            self.self_attention.forward(x,x,x,decoder_mask)\n",
    "            )\n",
    "\n",
    "        # x_tilde + x -> add + normalisation -> z\n",
    "        z = self.ff_layer_norm(x_tilde + x)\n",
    "\n",
    "        #x_tilde_normalised + encoder_out -> cross attention + dropout -> z_tilde\n",
    "        z_tilde = self.dropout(\n",
    "            self.cross_attention.forward(z,encoder_out,encoder_out,encoder_mask)\n",
    "        )\n",
    "\n",
    "        # z + z_tilde -> add + normalisation -> w\n",
    "        w = self.ff_layer_norm(z + z_tilde)\n",
    "\n",
    "        # w -> FF + dropout -> w_tilde\n",
    "        w_tilde = self.dropout(\n",
    "            self.feed_forward(w)\n",
    "        )\n",
    "\n",
    "        # w_tilde + w -> add + normalisation -> Y\n",
    "        Y = self.ff_layer_norm(w + w_tilde)\n",
    "\n",
    "        return Y\n",
    "        # END TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dnhBKIIU9Fxw"
   },
   "source": [
    "La classe `Decoder` représente toutes les couches du décodeur. La fonction `forward` de cette classe doit appeler chacune des couches (`DecoderLayer`) une à la suite de l'autre en passant à la couche courante la sortie de la couche précédente. Les attributs `encoder_out`, `encoder_mask` et `decoder_mask` sont partagés entre toutes les couches `DecoderLayer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "MdjZSpzd2tRV"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, num_layers: int, model_dim: int, ff_dim: int, dropout_rate: int = 0.3, num_heads=8) -> None:\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.layers = nn.ModuleList(\n",
    "            [DecoderLayer(\n",
    "                model_dim=model_dim,\n",
    "                ff_dim=ff_dim,\n",
    "                dropout_rate=dropout_rate,\n",
    "                num_heads=num_heads,\n",
    "            ) for _ in range(num_layers)]\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor, encoder_out: torch.Tensor, encoder_mask: torch.LongTensor = None, decoder_mask: torch.LongTensor = None):\n",
    "        \"\"\"\n",
    "        Applique toutes les couches du décodeur consécutivement\n",
    "\n",
    "        Args :\n",
    "            x : Tenseur d'entrée du décodeur correspondant à la séquence de sortie\n",
    "            Taille : [batch_size, seq_length, model_dim]\n",
    "\n",
    "            encoder_out : Tenseur contenant la séquence d'entrée encodée par l'encodeur\n",
    "\n",
    "            encoder_mask : Tenseur contenant le masque qui sera utilisé par l'encodeur\n",
    "            pour cacher certains jetons (notamment les jetons [PAD])\n",
    "\n",
    "            decoder_mask : Tenseur contenant le masque qui sera utilisé par le décodeur\n",
    "            pour cacher certains jetons (notamment les jetons [PAD] et les jetons futurs)\n",
    "\n",
    "        Returns :\n",
    "        Tenseur après avoir appliqués les couches dans l'encodeur de taille\n",
    "        [batch_size, seq_length, model_dim]\n",
    "        \"\"\"\n",
    "        # TODO\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, encoder_out, encoder_mask, decoder_mask)\n",
    "        return x\n",
    "        # END TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rqH-GpDP9Fxw"
   },
   "source": [
    "#### 4.5 Transformer (8 points)\n",
    "\n",
    "L'architecture du Transformer est maintenant prête à être assemblée. En utilisant les différentes couches que vous avez implémentées, complétez la fonction `forward` de la classe `Transformer` qui, à partir de l'entrée de l'encodeur et du décodeur, génère la sortie du décodeur. L'architecture, telle que présentée précédemment, correspond à la figure suivante :\n",
    "\n",
    "![Transformer](images/transformer.png)\n",
    "\n",
    "La fonction forward doit passer les entrées à l'encodeur et au décodeur pour pouvoir générer une prédiction en fonction d'une entrée en appliquant les bons masques et encodages de position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "UMWUXGRC2tRV"
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TransformerConfig:\n",
    "\n",
    "    model_dim: int = 512\n",
    "    ff_dim: int = 2048\n",
    "\n",
    "    nb_encoder: int = 6\n",
    "    nb_decoder: int = 6\n",
    "\n",
    "    num_heads: int = 8\n",
    "\n",
    "    max_seq_length: int = MAX_LENGTH\n",
    "    vocab_size: int = VOCAB_SIZE\n",
    "    device: str = 'cpu'\n",
    "    pad_token_id: int = 0\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "\n",
    "    def __init__(self, config: TransformerConfig) -> None:\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.config = config\n",
    "        self.enc_embeddings = nn.Embedding(\n",
    "            num_embeddings=config.vocab_size,\n",
    "            embedding_dim=config.model_dim\n",
    "        )\n",
    "\n",
    "        self.dec_embeddings = nn.Embedding(\n",
    "            num_embeddings=config.vocab_size,\n",
    "            embedding_dim=config.model_dim\n",
    "        )\n",
    "\n",
    "        self.positional_embeddings = PositionalEmbedding(\n",
    "            max_seq_length=config.max_seq_length,\n",
    "            embedding_dim=config.model_dim\n",
    "        )\n",
    "\n",
    "        self.encoder = Encoder(config.nb_encoder, config.model_dim, config.ff_dim, num_heads=config.num_heads)\n",
    "        self.decoder = Decoder(config.nb_decoder, config.model_dim, config.ff_dim, num_heads=config.num_heads)\n",
    "\n",
    "        self.linear_projection = nn.Linear(config.model_dim, config.vocab_size)\n",
    "        self.device = config.device\n",
    "\n",
    "    def generate_mask(self, src, tgt):\n",
    "        \"\"\"\n",
    "        Génère les masques d'attentions pour l'encodeur et le décodeur du transformer en\n",
    "        se basant sur le jeton de pad donné dans la configuration du transformer. Dans le\n",
    "        cas du décodeur, un masque causal est également calculé pour empêcher les jetons\n",
    "        de porter leur attention sur les jetons futurs\n",
    "\n",
    "        Args :\n",
    "            src : Séquence d'entrée\n",
    "\n",
    "        \"\"\"\n",
    "        src_mask = (src != self.config.pad_token_id).unsqueeze(1).unsqueeze(2)\n",
    "        tgt_mask = (tgt != self.config.pad_token_id).unsqueeze(1).unsqueeze(3)\n",
    "        seq_length = tgt.size(1)\n",
    "        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool().to(self.device)\n",
    "        tgt_mask = tgt_mask & nopeak_mask\n",
    "        return src_mask, tgt_mask\n",
    "\n",
    "    def forward(self, encoder_x: torch.Tensor, decoder_x: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Génère la sortie du décodeur étant donné une entrée pour l'encodeur et une entrée\n",
    "        pour le décodeur\n",
    "\n",
    "        Args :\n",
    "            encoder_x : Tenseur d'entrée de l'encodeur\n",
    "            Taille : [batch_size, seq_length]\n",
    "\n",
    "            decoder_x : Tenseur d'entrée du décodeur\n",
    "            Taille : [batch_size, seq_length]\n",
    "\n",
    "        Returns :\n",
    "        Sortie du décodeur correspondant au prédictions du jeton le plus proche. Attention,\n",
    "        n'appliquez pas softmax sur ces prédictions. Ce tenseur devrait avoir une taille de\n",
    "        [batch_size, seq_length, vocab_size]\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO\n",
    "        src_mask,tgt_mask = self.generate_mask(encoder_x,decoder_x)\n",
    "        xInputEncoder = self.positional_embeddings.forward(\n",
    "                             self.enc_embeddings.forward(encoder_x))\n",
    "        zOutEncoder = self.encoder.forward(xInputEncoder,src_mask)\n",
    "\n",
    "        xInputDecoder = self.positional_embeddings(\n",
    "                            self.dec_embeddings(decoder_x))\n",
    "\n",
    "        zOutDecoder = self.decoder.forward(\n",
    "            xInputDecoder,\n",
    "            zOutEncoder,\n",
    "            src_mask,\n",
    "            tgt_mask)\n",
    "\n",
    "        return self.linear_projection(zOutDecoder)\n",
    "        # END TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "09w2xPmk9Fxw"
   },
   "source": [
    "### 5. Padding et coupure (5 points)\n",
    "\n",
    "Il est important, lors de l'entraînement que toutes les séquences aient la même longueur de texte, car le Transformer prend toujours un nombre fixe de jetons. Cette taille correspond à sa fenêtre de contexte. Afin de s'assurer que toutes les séquences de texte dans un lot d'entraînement soient de la même longueur, nous allons couper les séquences trop longues et ajouter des jetons à celles qui sont trop courtes. Le jeton qui sera ajouté sera le jeton de \"padding\" du tokenizer (`[PAD]`).\n",
    "\n",
    "Complétez la fonction `tokenize` de la classe `DataCollator` qui s'occupe d'appeler le tokenizer avec les textes passés en paramètre en spécifiant les paramètres suivants :\n",
    "- `padding`: `\"max_length\"` (Attention on veut la chaîne de charactère `\"max_length\"`, pas la variable)\n",
    "- `truncation`: `True`\n",
    "- `max_length`: La taille maximale passée dans le constructeur\n",
    "- `return_tensors`: `pt`\n",
    "- `return_token_type_ids`: `False`\n",
    "- `add_special_tokens`: `True`\n",
    "\n",
    "Complétez la fonction `__call__` qui s'occupe de prendre un lot de données (le lot/batch correspondant à un sous-ensemble de l'ensemble d'entraînement) et retourne les entrées de l'encodeur et du décodeur ainsi que la sortie du décodeur du Transformer. Vous devrez prendre le lot passé en paramètre et transformer les colonnes `sentence` et `concepts` du lot en jetons. Les jetons de la colonne `sentence` seront envoyés à l'encodeur et les jetons de la colonne `concepts` seront envoyés au décodeur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "FgvbPOmY9Fxw"
   },
   "outputs": [],
   "source": [
    "from typing import Dict, List, Union\n",
    "\n",
    "\n",
    "class DataCollator:\n",
    "    def __init__(self, tokenizer: Tokenizer, max_length: int, device: str = 'cpu') -> None:\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.device = device\n",
    "\n",
    "        self.pad_token_id = tokenizer.pad_token_id\n",
    "        self.bos_token_id = tokenizer.bos_token_id\n",
    "        self.eos_token_id = tokenizer.eos_token_id\n",
    "\n",
    "    def tokenize(self, texts):\n",
    "        \"\"\"\n",
    "        Transforme la séquence de textes en séquence d'indice de jetons\n",
    "\n",
    "        Args :\n",
    "            texts : Textes à transformer\n",
    "\n",
    "        Returns :\n",
    "        Indices des jetons des textes\n",
    "        \"\"\"\n",
    "        # TODO\n",
    "        tokens = self.tokenizer(texts, padding=\"max_length\", truncation=True, max_length=self.max_length, return_tensors=\"pt\", return_token_type_ids = False, add_special_tokens = True)\n",
    "        return tokens[\"input_ids\"].to(self.device)\n",
    "        # END TODO\n",
    "\n",
    "    def __call__(self, batch: List[Dict[str, Union[str, int]]]) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Transforme une batch contenant les colonnes target et concepts en les envoyant au tokenizer\n",
    "        et préparant les jetons aux entrées et sorties de l'encodeur et du décodeur\n",
    "        \"\"\"\n",
    "        # TODO :\n",
    "        sentences = [el['sentence'] for el in batch]\n",
    "        concepts = [el['concepts'] for el in batch]\n",
    "\n",
    "        encoder = self.tokenize(sentences) # ids des jetons des entrées\n",
    "        decoder = self.tokenize(concepts) # ids des jetons des sorties\n",
    "        # END TODO\n",
    "\n",
    "        \"\"\"\n",
    "        Dans le décodeur, la séquence attendue est décalée vers la droite d'un jeton à l'entrée du décodeur.\n",
    "        Par exemple, si on veut faire de la traduction, nous pourrions avoir la séquence suivante :\n",
    "\n",
    "        La pomme est verte -> The apple is green\n",
    "\n",
    "        Les valeurs du dictionnaire de retour serait donc :\n",
    "\n",
    "        +-------------+--------+--------+--------+--------+--------+--------+\n",
    "        |   Valeur    | Jeton1 | Jeton2 | Jeton3 | Jeton4 | Jeton5 | Jeton6 |\n",
    "        +-------------+--------+--------+--------+--------+--------+--------+\n",
    "        | encoder_in  | [BOS]  | la     | pomme  | est    | verte  | [EOS]  |\n",
    "        | decoder_in  | [BOS]  | The    | apple  | is     | green  | [EOS]  |\n",
    "        | decoder_out | The    | apple  | is     | green  | [EOS]  | [PAD]  |\n",
    "        +-------------+--------+--------+--------+--------+--------+--------+\n",
    "\n",
    "        Par exemple, pour le jeton 3, le transformer essaiera de prédire le jeton \"is\" avec comme information\n",
    "        tous les jetons de l'encodeur et tous les jetons précédents le \"is\" ([BOS] The apple).\n",
    "\n",
    "        C'est d'ailleurs à cause de ce décalage que nous enlevons le premier jetons dans 'decoder_out'. Aussi,\n",
    "        le dernier jetons dans 'decoder_in' est enlevé, car le Transformer ne devrait jamais voir le jeton\n",
    "        de fin de phrase, car cela voudrait dire que la séquence est terminée. Il devrait seulement le prédire.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'encoder_in': encoder.to(self.device),\n",
    "            'decoder_in': decoder[:, :-1].to(self.device),\n",
    "            'decoder_out': decoder[:, 1:].to(self.device),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ms_zfOuw9Fxw",
    "outputId": "09ec769e-5f6c-46c1-b2d2-c62463323a4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "\n",
      "Encoder in detokenized : \n",
      "\n",
      " [BOS]two elephants standing next to each other in their pen [EOS][PAD][PAD][PAD][PAD]\n",
      "[BOS]A big elephant that is standing there quietly in the pen . [EOS]\n",
      "\n",
      "Decoder in detokenized : \n",
      "\n",
      " [BOS][ ' elephant ' ' pen ' ' stand ' ] [EOS][PAD][PAD]\n",
      "[BOS][ ' elephant ' ' pen ' ' stand ' ] [EOS][PAD][PAD]\n",
      "\n",
      "Decoder out detokenized : \n",
      "\n",
      " [ ' elephant ' ' pen ' ' stand ' ] [EOS][PAD][PAD][PAD]\n",
      "[ ' elephant ' ' pen ' ' stand ' ] [EOS][PAD][PAD][PAD]\n",
      "\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "def test_data_collator():\n",
    "    data_collator = DataCollator(tokenizer=tokenizer, max_length=16)\n",
    "    sample_data = test_dataset[:2]\n",
    "    result = data_collator(CustomDataset(data=sample_data))\n",
    "    print('=' * 100)\n",
    "    print()\n",
    "    print('Encoder in detokenized : \\n\\n', '\\n'.join(tokenizer.batch_decode(result['encoder_in'])))\n",
    "    print()\n",
    "    print('Decoder in detokenized : \\n\\n', '\\n'.join(tokenizer.batch_decode(result['decoder_in'])))\n",
    "    print()\n",
    "    print('Decoder out detokenized : \\n\\n', '\\n'.join(tokenizer.batch_decode(result['decoder_out'])))\n",
    "    print()\n",
    "    print('=' * 100)\n",
    "\n",
    "test_data_collator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ft9grnXB9Fxw"
   },
   "source": [
    "Sortie attendue :\n",
    "```\n",
    "====================================================================================================\n",
    "\n",
    "Encoder in detokenized :\n",
    "\n",
    " [BOS]two elephants standing next to each other in their pen [EOS][PAD][PAD][PAD][PAD]\n",
    "[BOS]A big elephant that is standing there quietly in the pen. [EOS]\n",
    "\n",
    "Decoder in detokenized :\n",
    "\n",
    " [BOS]['elephant'' pen'' stand'] [EOS][PAD][PAD]\n",
    "[BOS]['elephant'' pen'' stand'] [EOS][PAD][PAD]\n",
    "\n",
    "Decoder out detokenized :\n",
    "\n",
    " ['elephant'' pen'' stand'] [EOS][PAD][PAD][PAD]\n",
    "['elephant'' pen'' stand'] [EOS][PAD][PAD][PAD]\n",
    "\n",
    "====================================================================================================\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GrA7t_Xy9Fxw"
   },
   "source": [
    "### 6. Création de lots (Batching)\n",
    "\n",
    "Nous allons utiliser la classe `DataLoader` de PyTorch pour charger les données en \"batchs\". La classe `DataCollator` sera passée en paramètre lors du chargement des données pour automatiquement transformer le texte en jetons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "lptJkGPm9Fxw"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "TEST_BATCH_SIZE = 128\n",
    "\n",
    "collator = DataCollator(tokenizer=tokenizer, max_length=MAX_LENGTH, device=DEVICE)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collator)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collator)\n",
    "test_loader = DataLoader(test_dataset, batch_size=TEST_BATCH_SIZE, shuffle=False, collate_fn=collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kE5pV2-d4Px-",
    "outputId": "a7407c0c-822d-45df-8f75-c37f3f90d35f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'encoder_in': tensor([[   1,  437, 1004,  ...,    0,    0,    0],\n",
       "         [   1,  228, 2955,  ...,    0,    0,    0],\n",
       "         [   1,   80,  159,  ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [   1,   99,  602,  ...,    0,    0,    0],\n",
       "         [   1,  679,  511,  ...,    0,    0,    0],\n",
       "         [   1,  364, 1292,  ...,    0,    0,    0]], device='cuda:0'),\n",
       " 'decoder_in': tensor([[  1, 106,  91,  ...,   2,   0,   0],\n",
       "         [  1, 106,  91,  ...,   2,   0,   0],\n",
       "         [  1, 106,  91,  ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [  1, 106,  91,  ...,   2,   0,   0],\n",
       "         [  1, 106,  91,  ...,   2,   0,   0],\n",
       "         [  1, 106,  91,  ...,   2,   0,   0]], device='cuda:0'),\n",
       " 'decoder_out': tensor([[ 106,   91, 1004,  ...,    0,    0,    0],\n",
       "         [ 106,   91,  228,  ...,    0,    0,    0],\n",
       "         [ 106,   91,  254,  ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [ 106,   91,  356,  ...,    0,    0,    0],\n",
       "         [ 106,   91,  540,  ...,    0,    0,    0],\n",
       "         [ 106,   91,  956,  ...,    0,    0,    0]], device='cuda:0')}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7R_9-0va9Fxw"
   },
   "source": [
    "### 7. Entraînement (26 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9BCgDQaf9Fxw"
   },
   "source": [
    "#### 7.1 Boucle d'entraînement (20 points)\n",
    "\n",
    "Pour pouvoir générer des prédictions qui ont du sens, il faut entraîner le modèle à effectuer ces prédictions à partir des données d'entraînement. Pour cela, la classe `Trainer` sera utilisée. Elle permettra au modèle, à partir de données d'entraînement, d'apprendre la bonne combinaison de paramètres qui effectue les meilleures prédictions. Nous validerons ensuite les prédictions avec l'ensemble de test. L'ensemble de validation sera utilisé durant l'entraînement pour s'assurer que le modèle apprend bien.\n",
    "\n",
    "Compléter les fonctions `train_epoch` et `validation_epoch` de la classe `Trainer` pour permettre au transformer passé en paramètre du constructeur d'être entraîné avec les données d'entraînement.\n",
    "\n",
    "La fonction `train_epoch` doit :\n",
    "- Parcourir toutes les lots (batchs) d'entraînement et pour chaque lot :\n",
    "  - Entraîner le modèle pour ce lot en évaluant la fonction de perte et mettant à jour les paramètres en fonction des gradients\n",
    "- Calculer la perte d'entraînement moyenne\n",
    "- Mettre la perte d'entraînement dans un objet de la classe `History`\n",
    "\n",
    "La fonction `validation_epoch` doit :\n",
    "- Parcourir tous les lots de validation et pour chaque lot :\n",
    "  - Évaluer le modèle sur ce lot en évaluant la fonction de perte\n",
    "- Calculer la perte de validation moyenne\n",
    "- Mettre la perte de validation dans un objet de la classe `History`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "HhqDUPeB2tRV"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "class History:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.t_loss = []\n",
    "        self.v_loss = []\n",
    "        self.time_to_train = -1\n",
    "\n",
    "class Trainer:\n",
    "\n",
    "    def __init__(self,\n",
    "                 transformer: Transformer,\n",
    "                 train_loader: DataLoader,\n",
    "                 val_loader: DataLoader,\n",
    "                 num_epochs: int,\n",
    "                 loss_function = None,\n",
    "                 device='cpu',\n",
    "                 saving_path='model') -> None:\n",
    "        \"\"\"\n",
    "        Args :\n",
    "            transformer: Modèle qui sera entraîné\n",
    "\n",
    "            train_loader: Objet contenant les données d'entraînement en batch\n",
    "\n",
    "            val_loader: Objet contenant les données de validation en batch\n",
    "\n",
    "            num_epochs: Nombre d'étape d'entraînement (une étape équivaut à\n",
    "            parcourir toutes les données une fois)\n",
    "\n",
    "            loss_function: Fonction de perte utilisée lors de l'entraînement. Si\n",
    "            le paramètre est laissé à `None`, la fonction d'entropie croisée sera\n",
    "            utilisée en ignorant les jetons de pad (retrouvés avec la config du modèle)\n",
    "\n",
    "            device: Machine sur laquelle le modèle sera entraîné\n",
    "        \"\"\"\n",
    "\n",
    "        self.model = transformer\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.num_epochs = num_epochs\n",
    "        self.device = device\n",
    "        self.saving_path = saving_path\n",
    "\n",
    "        self.optimizer = O.Adam(self.model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "        if loss_function is None:\n",
    "            self.loss_function = nn.CrossEntropyLoss(ignore_index=transformer.config.pad_token_id).to(self.device)\n",
    "        else:\n",
    "            self.loss_function = loss_function\n",
    "\n",
    "    def compute_loss(self, logits: torch.Tensor, labels: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Trouve la valeur de la fonction de perte (self.loss_function)\n",
    "        étant donné les probabilités (logits) prédits et les vraies\n",
    "        valeurs (labels)\n",
    "\n",
    "        Args :\n",
    "            logits:     Probabilités prédites par le modèle sur le prochain\n",
    "                        jeton pour chacun des jetons de la séquence\n",
    "                        Tenseur de taille : [batch_size, seq_length, vocab_size]\n",
    "\n",
    "            labels:     Jetons qui devraient être prédis comme les prochains\n",
    "                        jetons pour chaque jeton de la séquence\n",
    "                        Tenseur de taille : [batch_size, seq_length]\n",
    "        \"\"\"\n",
    "\n",
    "        _, _, vocab_size = logits.shape\n",
    "        return self.loss_function(logits.contiguous().view(-1, vocab_size), labels.contiguous().view(-1))\n",
    "\n",
    "    def train_epoch(self, history):\n",
    "        \"\"\"\n",
    "        Entraîne le modèle sur tous les lots du `self.train_loader` et calcule\n",
    "        la perte d'entraînement moyen en l'ajoutant à l'objet history passé en\n",
    "        paramètre\n",
    "\n",
    "        Args :\n",
    "            history :   Objet contenant les statistiques d'entraînement d'un modèle\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO\n",
    "        self.model.train()\n",
    "        train_loss = 0\n",
    "\n",
    "        for batch in self.train_loader:\n",
    "\n",
    "          encoder_in = batch['encoder_in'].to(device)\n",
    "          decoder_in = batch['decoder_in'].to(device)\n",
    "          decoder_out = batch['decoder_out'].to(device)\n",
    "\n",
    "\n",
    "          y_pred = self.model(encoder_in, decoder_in)\n",
    "\n",
    "          loss = self.compute_loss(y_pred, decoder_out)\n",
    "          train_loss += loss\n",
    "\n",
    "          self.optimizer.zero_grad()\n",
    "          loss.backward()\n",
    "          self.optimizer.step()\n",
    "\n",
    "\n",
    "        history.t_loss.append(train_loss / len(self.train_loader))\n",
    "\n",
    "\n",
    "        # END TODO\n",
    "\n",
    "    def validation_epoch(self, history):\n",
    "        \"\"\"\n",
    "        Évalue le modèle sur tous les lots du `self.val_loader` et calcule\n",
    "        la perte de validation moyen en l'ajoutant à l'objet history passé en\n",
    "        paramètre\n",
    "\n",
    "        Args :\n",
    "            history :   Objet contenant les statistiques d'entraînement d'un modèle\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO\n",
    "        self.model.eval()\n",
    "        eval_loss = 0\n",
    "\n",
    "        for batch in self.val_loader:\n",
    "\n",
    "          encoder_in = batch['encoder_in'].to(device)\n",
    "          decoder_in = batch['decoder_in'].to(device)\n",
    "          decoder_out = batch['decoder_out'].to(device)\n",
    "\n",
    "\n",
    "          y_pred = self.model(encoder_in, decoder_in)\n",
    "          loss = self.compute_loss(y_pred, decoder_out)\n",
    "\n",
    "          eval_loss += loss\n",
    "\n",
    "        history.v_loss.append(eval_loss / len(self.val_loader))\n",
    "        # END TODO\n",
    "\n",
    "\n",
    "    def train(self) -> History:\n",
    "        \"\"\"\n",
    "        Entraîne `self.model` en utilisant les données de `self.train_loader`\n",
    "\n",
    "        Returns :\n",
    "        Historique contenant les perte d'entraînement et de validation moyennes\n",
    "        pour chaque étape (epoch) d'entraînement\n",
    "        \"\"\"\n",
    "        history = History()\n",
    "        start = time.time()\n",
    "        self.model.to(self.device)\n",
    "\n",
    "\n",
    "        for epoch in range(self.num_epochs):\n",
    "\n",
    "            self.train_epoch(history)\n",
    "            self.validation_epoch(history)\n",
    "\n",
    "            print(f'Epoch {epoch} / {self.num_epochs} : train_loss = {history.t_loss[-1]}, val_loss = {history.v_loss[-1]}')\n",
    "\n",
    "            if epoch > 0 and epoch % 10 == 0:\n",
    "                self.save(f'{self.saving_path}_{epoch}.pt')\n",
    "\n",
    "        end = time.time()\n",
    "        history.time_to_train = end - start\n",
    "        self.save(f'{self.saving_path}_{self.num_epochs}.pt')\n",
    "        return history\n",
    "\n",
    "    def save(self, path: str):\n",
    "        \"\"\"\n",
    "        Saves the model in the specified path\n",
    "        \"\"\"\n",
    "        torch.save(self.model.state_dict(), path)\n",
    "\n",
    "    @staticmethod\n",
    "    def load(config: TransformerConfig, path: str):\n",
    "        \"\"\"\n",
    "        Loads the model from the specified path\n",
    "        \"\"\"\n",
    "        model = Transformer(config)\n",
    "        model.load_state_dict(torch.load(path))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rh33P37P9Fxx"
   },
   "source": [
    "#### 7.2 Nombre de paramètres (2 points)\n",
    "Complétez maintenant la fonction `count_parameters` permettant de calculer le nombre de paramètres du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mUnb2fRp2tRV",
    "outputId": "50636907-0802-4c62-9a21-1c1dbdc830e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de paramètres :  None\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    \"\"\"\n",
    "    Calcule le nombre de paramètres que l'on peut entraîner dans un modèle\n",
    "\n",
    "    Args :\n",
    "        model : Modèle dont on veut savoir le nombre de paramètres\n",
    "\n",
    "    Returns :\n",
    "    Nombre de paramètres\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    pass\n",
    "    # END TODO\n",
    "\n",
    "config = TransformerConfig()\n",
    "config.device = DEVICE\n",
    "model = Transformer(config)\n",
    "\n",
    "print('Nombre de paramètres : ', count_parameters(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VyvX8Loe2tRV"
   },
   "source": [
    "#### 7.3 Entraînement (4 points)\n",
    "Entraînez maintenant le modèle pour 30 époques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "Cf6Q-9v12tRc"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(model,train_loader,val_loader, num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, loss_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[27], line 152\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_epochs):\n\u001b[1;32m--> 152\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidation_epoch(history)\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m / \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m : train_loss = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhistory\u001b[38;5;241m.\u001b[39mt_loss[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, val_loss = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhistory\u001b[38;5;241m.\u001b[39mv_loss[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[27], line 92\u001b[0m, in \u001b[0;36mTrainer.train_epoch\u001b[1;34m(self, history)\u001b[0m\n\u001b[0;32m     88\u001b[0m decoder_in \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdecoder_in\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     89\u001b[0m decoder_out \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdecoder_out\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 92\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_in\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss(y_pred, decoder_out)\n\u001b[0;32m     95\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[22], line 84\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, encoder_x, decoder_x)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# TODO\u001b[39;00m\n\u001b[0;32m     82\u001b[0m src_mask,tgt_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_mask(encoder_x,decoder_x)\n\u001b[0;32m     83\u001b[0m xInputEncoder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositional_embeddings\u001b[38;5;241m.\u001b[39mforward(\n\u001b[1;32m---> 84\u001b[0m                      \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menc_embeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder_x\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     85\u001b[0m zOutEncoder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m.\u001b[39mforward(xInputEncoder,src_mask)\n\u001b[0;32m     87\u001b[0m xInputDecoder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositional_embeddings(\n\u001b[0;32m     88\u001b[0m                     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdec_embeddings(decoder_x))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:190\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\functional.py:2551\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2545\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2546\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2547\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2548\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2549\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2550\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2551\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "device = torch.device(\"cpu\")\n",
    "trainer = Trainer(model,train_loader,val_loader, num_epochs=30, loss_function=None, device=\"cpu\")\n",
    "history = trainer.train() # Mettez le résultat de l'entraînement dans cette variable\n",
    "# END TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VHosfEok6c0_"
   },
   "source": [
    "### 8. Historique d'entraînement (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "paXl6ZeL9Fxx"
   },
   "source": [
    "#### 8.1 Graphique (2 points)\n",
    "Complétez la fonction `show_history` qui affiche l'historique d'entraînement (perte d'entraînement et perte de validation par époque, utilisez des pas de 5 époques) du modèle dans un graphe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w9oPTKOB9Fxx"
   },
   "outputs": [],
   "source": [
    "def show_history(history: History):\n",
    "    \"\"\"\n",
    "    Affiche l'historique d'entraînement du modèle dans un graphique\n",
    "\n",
    "    Args :\n",
    "        history : Objet contenant les pertes d'entraînement et de\n",
    "        validation de chaque étape d'entraînement\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    pass\n",
    "    # END TODO\n",
    "\n",
    "show_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9LwB7-VX9Fxx"
   },
   "source": [
    "#### 8.2 Est-ce que le modèle semble être en sur-apprentissage ? Pourquoi ? Que feriez-vous pour résoudre ce problème ? (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IndyxKRWBFiQ"
   },
   "source": [
    "#### 8.3 Lors de l'entraînement, un modèle a été sauvegardé à chaque 10 époques. En vous basant sur le graphique de la fonction de perte durant l'entraînement, choisissez la sauvegarde du modèle qui n'est pas en sur-apprentissage et chargez le pour l'évaluation à l'aide de la fonction `load` de la classe `Trainer`. Chargez également le dernier modèle sauvegardé pour comparer les résultats. (1 point)\n",
    "\n",
    "Nous dénoterons le modèle arrêté avant le sur-apprentissage comme étant : `stopped_model`\n",
    "\n",
    "Nous dénoterons le dernier modèle sauvegardé comme étant : `last_model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O96q-EK2BZr9"
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "# Mettez vos deux modèles entraînés dans ces variables pour la suite\n",
    "stopped_model = None\n",
    "last_model = None\n",
    "\n",
    "# END TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W95hjKY19Fxx"
   },
   "source": [
    "### 9. Évaluation (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oM_j2M0A9Fxx",
    "tags": []
   },
   "source": [
    "#### 9.1 Génération (10 points)\n",
    "Maintenant que le modèle est entraîné, nous pouvons tester ses générations. Complétez la fonction `generate` qui génère, pour un lot de données, les prédictions d'un modèle sur les concepts clés de la phrase donnée en paramètre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UmoO5WYT9Fxx"
   },
   "outputs": [],
   "source": [
    "def generate(model: Transformer, encoder_in: torch.tensor, bos_token_id: int, eos_token_id: int, max_length=MAX_LENGTH):\n",
    "    \"\"\"\n",
    "    Génère les prédictions d'un modèle pour des phrases données en paramètre. Pour cela, vous devez\n",
    "    initialiser un tenseur X contenant les jetons de début de phrase (bos_token_id). Ensuite, ce\n",
    "    tenseur sera passé comme entrée au décodeur avec `encoder_in` comme entrée à l'encodeur. Le modèle\n",
    "    génèrera un jeton en sortie qui sera le jeton le plus probable étant donné le jeton de début de\n",
    "    phrase et la séquence passée dans l'encodeur. Ce jeton devra être concaténé au tenseur initial X\n",
    "    pour former une séquence de deux jetons. Cette nouvelle séquence est ensuite réenvoyée au décodeur.\n",
    "    Un jeton en sortie sera généré correspondant au jeton le plus probable étant donné la séquence de\n",
    "    deux jetons et l'entrée de l'encodeur. Le nouveau jeton est concaténé au tenseur X et l'opération\n",
    "    est répétée jusqu'à ce que le décodeur génère le jeton de fin de phrase.\n",
    "\n",
    "    Args :\n",
    "        model : Modèle effectuant les prédictions\n",
    "\n",
    "        inputs : Tenseur contenant les phrases d'entrées sous forme d'indices de jetons\n",
    "\n",
    "        bos_token_id : Jeton d'entrée du tokenizer utilisé pour initialiser le tenseur de génération\n",
    "\n",
    "        eos_token_id : Jeton de fin du tokenizer utilisé pour détecter la fin d'une séquence\n",
    "\n",
    "        max_length : Nombre maximal de jetons qui doivent être générés par le modèle\n",
    "\n",
    "    Returns :\n",
    "    Génération du modèle de chacune des phrases en entrée\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    pass\n",
    "    # END TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5t_4T4Eg9Fxx"
   },
   "outputs": [],
   "source": [
    "def get_predictions(model, tokenizer):\n",
    "\n",
    "    bos_token_id = tokenizer(\"\")['input_ids'][0]\n",
    "    eos_token_id = tokenizer(\"\")['input_ids'][1]\n",
    "\n",
    "    sentences = []\n",
    "    predictions = []\n",
    "    ground_truth = []\n",
    "    for test_data in test_loader:\n",
    "\n",
    "        inputs = test_data['encoder_in']\n",
    "        result = generate(model, inputs, bos_token_id, eos_token_id)\n",
    "\n",
    "        sentences.extend(tokenizer.batch_decode(test_data['encoder_in'], skip_special_tokens=True))\n",
    "        ground_truth.extend(tokenizer.batch_decode(test_data['decoder_out'], skip_special_tokens=True))\n",
    "        predictions.extend(tokenizer.batch_decode(result, skip_special_tokens=True))\n",
    "\n",
    "    return sentences, ground_truth, predictions\n",
    "\n",
    "sentences_stopped, ground_truth_stopped, predictions_stopped = get_predictions(stopped_model, tokenizer)\n",
    "sentences_last, ground_truth_last, predictions_last = get_predictions(last_model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2e8pOemw9Fxx"
   },
   "outputs": [],
   "source": [
    "predictions_stopped = pd.DataFrame({'sentences': sentences_stopped, 'ground_truth': ground_truth_stopped, 'predictions': predictions_stopped})\n",
    "predictions_last = pd.DataFrame({'sentences': sentences_last, 'ground_truth': ground_truth_last, 'predictions': predictions_last})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vGOifYaW9Fxx"
   },
   "source": [
    "#### 9.2 Évaluation naive de la génération (1 point)\n",
    "Nous allons d'abord mesurer l'efficacité de notre modèle pour extraire les concepts à l'aide d'une métrique de correspondance exacte (exact match). Pour cela, nous allons mesurer le nombre de générations (`predictions`) qui sont identiques à celles qui sont attendues dans l'ensemble de référence (`ground truth`) et diviser le tout par le nombre totaux d'éléments dans l'ensemble de référence. Ainsi, la métrique EM (exact match) équivaut à :\n",
    "\n",
    "$$\\text{EM} = \\frac{\\text{Nombre d'éléments identiques entre l'ensemble généré et l'ensemble de référence}}{\\text{Nombre d'éléments dans l'ensemble de référence}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3owRHw1D9Fxx"
   },
   "outputs": [],
   "source": [
    "def compute_em_score(data):\n",
    "    \"\"\"\n",
    "    Évalue la métrique EM du modèle en utilisant la métrique BLEU\n",
    "    Args :\n",
    "        - data : DataFrame contenant les colonnes predictions et ground_truth\n",
    "\n",
    "    Returns :\n",
    "    La métrique EM du modèle en pourcentage\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    pass\n",
    "    # END TODO\n",
    "\n",
    "print(f\"La métrique EM du modèle arrêté selon la fonction de perte est {compute_em_score(predictions_stopped):.2f} %\")\n",
    "print(f\"La métrique EM du dernier modèle est {compute_em_score(predictions_last):.2f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8TlJ99y99Fxy"
   },
   "source": [
    "#### 9.3 Quels problèmes voyez-vous avec cette manière de calculer la performance du modèle ? (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v5TGstQP9Fxy"
   },
   "source": [
    "#### 9.4 Métrique BLEU (4 points)\n",
    "Pour pallier à ce problème, la métrique BLEU sera utilisée puisqu'elle est basée sur le nombre de n-gramme qui sont présents dans les prédictions et les séquences voulues. La formule est donnée ci-dessous :\n",
    "$$BLEU = BP * exp \\Big( \\sum_{n=1}^{N} w_n \\log p_n \\Big)$$\n",
    "\n",
    "Considérant que $r$ est la phrase de référence (voulue) et $c$ la phrase générée (candidate), $p_n$ est la précision modifiée pour le n-gramme (correspondant au ratio de la fréquence maximum du n-gramme dans la phrase de référence par la fréquence du n-gramme):\n",
    "$$p_n = \\frac{\\sum_{\\text{n-gramme} \\in c} \\min\\Big( \\max_{r} \\text{Count$_r$(n-gramme)}, \\text{Count$_c$(n-gramme)} \\Big)}{\\sum_{\\text{n-gramme} \\in c} \\text{Count$_c$(n-gramme)}}$$\n",
    "\n",
    "Notez que le $\\max_{r}$ est présent ici car BLEU accepte plusieurs phrases de référence pour une même phrase générée. Cependant, dans notre cas, il y a seulement une seule phrase de référence.\n",
    "\n",
    "Posons ensuite $|r|$ comme le nombre de mots dans la phrase cible et $|c|$ comme le nombre de mots dans la phrase prédite. Si $c>r$, alors BP vaut 1. Sinon $$BP = exp(1 - \\frac{|r|}{|c|})$$\n",
    "\n",
    "Les valeurs des poids $w_n$ est ce qui donne les différentes variations de la métrique BLEU. Dans notre cas, la métrique BLEU-1 sera utilisée. La valeur maximale du score BLEU est 1 et la valeur minimale est 0.\n",
    "\n",
    "Vous pouvez utiliser la fonction `sentence_bleu` de `nltk` pour calculer votre score BLEU. N'oubliez pas d'enlever les apostrophes et les crochets des générations avant votre calcul."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dChq1yTK9Fxy"
   },
   "outputs": [],
   "source": [
    "def compute_bleu(predictions):\n",
    "    \"\"\"\n",
    "    Évalue la précision du modèle en utilisant la métrique BLEU\n",
    "    Args :\n",
    "        - data : DataFrame contenant les colonnes predictions et ground_truth\n",
    "\n",
    "    Returns :\n",
    "        La moyenne du score BLEU\n",
    "    \"\"\"\n",
    "    weights = (1, 0, 0, 0) # Use Bleu-1\n",
    "    # TODO\n",
    "    pass\n",
    "    # END TODO\n",
    "\n",
    "print(f\"Le score BLEU du modèle arrêté selon la fonction de perte est {compute_bleu(predictions_stopped):.2f}\")\n",
    "print(f\"Le score BLEU du dernier modèle est {compute_bleu(predictions_last):.2f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rZ2DjH3ZeRVO"
   },
   "source": [
    "#### 9.5 Quel est l'avantage d'utiliser la métrique BLEU par rapport à la métrique EM basée sur la comparaison de chaîne de caractères ? (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f06F1OICfO7_"
   },
   "source": [
    "#### 9.6 Que remarquez-vous par rapport aux performances du modèle arrêté avant le sur-apprentissage selon la fonction de perte versus celles du dernier modèle ? Quelles sont les raisons qui peuvent expliquer cela ? (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C2cXyEuA9Fxy"
   },
   "source": [
    "### 10. Exploration (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U99e4YjL9Fxy"
   },
   "source": [
    "#### 10.1 Explorez les générations actuelles de votre modèle et ressortez 2 problèmes que le modèle a lors de la génération qui font diminuer son score BLEU. (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JfdKeifU9Fxy"
   },
   "source": [
    "#### 10.2 Amélioration des métriques (2 points)\n",
    "L'exemple ci-dessous montre 2 générations de 2 modèles pour la phrase \"A dog is eating a flower\". Bien que la génération du modèle 2 soit beaucoup plus proche sémantiquement de la référence que celle du modèle 1, la métrique BLEU retourne 0.0 dans les deux cas. En effet, puisque la métrique ne compare que les n-grammes, la prédiction du modèle 2 est quand même de 0, car aucun des mots dans la prédiction ne sont présents dans les concepts voulus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gd8Y64Pv9Fxy"
   },
   "outputs": [],
   "source": [
    "ground_truth = \"['dog' 'eat' 'flower']\"\n",
    "\n",
    "prediction_1 = \"['car' 'hit' 'person']\"\n",
    "preds = pd.DataFrame({'predictions': [prediction_1], 'ground_truth': [ground_truth]})\n",
    "\n",
    "print(f\"Concepts voulus {ground_truth}\")\n",
    "print(f\"Prédiction du modèle 1 : {prediction_1}\")\n",
    "print(f\"BLEU : {compute_bleu(preds):.2f}\")\n",
    "\n",
    "prediction_2 = \"['animal' 'eating' 'plant']\"\n",
    "preds = pd.DataFrame({'predictions': [prediction_2], 'ground_truth': [ground_truth]})\n",
    "\n",
    "print(f\"Prédiction du modèle 2 : {prediction_2}\")\n",
    "print(f\"BLEU : {compute_bleu(preds):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OLVBUJ2e9Fxy"
   },
   "source": [
    "Proposez (sans l'implémenter) une meilleure métrique pour évaluer les modèles face à cette tâche d'extraction qui donnerait un score plus élevé à la prédiction du modèle 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nbouxl3_6c1C"
   },
   "source": [
    "## Livrables\n",
    "Vous devez remettre votre notebook sur Moodle et Gradescope en ipynb et pdf. Pour Gradescope vous devez associer les numéros de questions avec vos réponses dans le pdf grâce à l'outil que fournit Gradescope.\n",
    "\n",
    "\n",
    "## Évaluation\n",
    "Votre TP sera évalué selon les critères suivants :\n",
    "1. Exécution correcte du code et obtention des sorties attendues\n",
    "2. Réponses correctes aux questions d'analyse\n",
    "3. Qualité du code (noms significatifs, structure, performance, gestion d’exception, etc.)\n",
    "4. Commentaires clairs et informatifs"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
